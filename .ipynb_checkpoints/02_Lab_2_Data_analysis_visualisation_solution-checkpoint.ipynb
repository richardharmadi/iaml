{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introductory applied machine learning (INFR09029)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 2: Data analysis and visualisation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this lab we work with a spam filtering dataset and we perform exploratory data analysis, visualisation and, finally, we learn how to perform classification tasks using Naive Bayes. We introduce the `sci-kit learn` package or simply `sklearn` which is a machine learning library for Python which works with numpy array objects."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we need to import the packages we will be using through this lab:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Import packages\n",
    "from __future__ import division, print_function # Imports from __future__ since we're running Python 2\n",
    "import os\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Launch a qtconsole\n",
    "%qtconsole"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Clarifications*:\n",
    "\n",
    "* The `%matplotlib inline` command forces the matplotlib plots to be rendered within the notebook.\n",
    "* The `qtconsole` command will launch an IPython (Jupyter) command line console which will connect to the current Jupyter kernel. This can be particularly useful when you want to try out various things without messing up the cells in our notebook. For instance, think of the situation where you want to find out the value of a variable (or numpy array); instead of having to create a new cell, display the value (or array) and then delete the cell you can just type the variable name in the console window."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spambase dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the first part we consider the [Spambase](http://archive.ics.uci.edu/ml/datasets/Spambase) dataset, consisting of tagged emails from a single email account. Read through the description available for this data to get a feel for what you're dealing with. The data has been converted to `.csv` format for you:\n",
    "\n",
    "Download the dataset and save it in a directory called `datasets` in the same folder that your notebooks live. Alternatively, you can save the dataset in any folder you wish and modify the `data_path` variable accordingly. We will load our data in a pandas DataFrame structure. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "data_path = os.path.join(os.getcwd(), 'datasets', 'spambase.csv')\n",
    "spambase = pd.read_csv(data_path, delimiter = ',')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have now loaded the data. Let's get a feeling of what the data looks like by using the `head()` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word_freq_make</th>\n",
       "      <th>word_freq_address</th>\n",
       "      <th>word_freq_all</th>\n",
       "      <th>word_freq_3d</th>\n",
       "      <th>word_freq_our</th>\n",
       "      <th>word_freq_over</th>\n",
       "      <th>word_freq_remove</th>\n",
       "      <th>word_freq_internet</th>\n",
       "      <th>word_freq_order</th>\n",
       "      <th>word_freq_mail</th>\n",
       "      <th>...</th>\n",
       "      <th>char_freq_;</th>\n",
       "      <th>char_freq_(</th>\n",
       "      <th>char_freq_[</th>\n",
       "      <th>char_freq_!</th>\n",
       "      <th>char_freq_$</th>\n",
       "      <th>char_freq_#</th>\n",
       "      <th>capital_run_length_average</th>\n",
       "      <th>capital_run_length_longest</th>\n",
       "      <th>capital_run_length_total</th>\n",
       "      <th>is_spam</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.778</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>3.756</td>\n",
       "      <td>61.0</td>\n",
       "      <td>278.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.21</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.94</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.132</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.372</td>\n",
       "      <td>0.180</td>\n",
       "      <td>0.048</td>\n",
       "      <td>5.114</td>\n",
       "      <td>101.0</td>\n",
       "      <td>1028.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.06</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.23</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.25</td>\n",
       "      <td>...</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.143</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.276</td>\n",
       "      <td>0.184</td>\n",
       "      <td>0.010</td>\n",
       "      <td>9.821</td>\n",
       "      <td>485.0</td>\n",
       "      <td>2259.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.63</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.137</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.137</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>3.537</td>\n",
       "      <td>40.0</td>\n",
       "      <td>191.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.63</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.135</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.135</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>3.537</td>\n",
       "      <td>40.0</td>\n",
       "      <td>191.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 58 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   word_freq_make  word_freq_address  word_freq_all  word_freq_3d  \\\n",
       "0            0.00               0.64           0.64           0.0   \n",
       "1            0.21               0.28           0.50           0.0   \n",
       "2            0.06               0.00           0.71           0.0   \n",
       "3            0.00               0.00           0.00           0.0   \n",
       "4            0.00               0.00           0.00           0.0   \n",
       "\n",
       "   word_freq_our  word_freq_over  word_freq_remove  word_freq_internet  \\\n",
       "0           0.32            0.00              0.00                0.00   \n",
       "1           0.14            0.28              0.21                0.07   \n",
       "2           1.23            0.19              0.19                0.12   \n",
       "3           0.63            0.00              0.31                0.63   \n",
       "4           0.63            0.00              0.31                0.63   \n",
       "\n",
       "   word_freq_order  word_freq_mail   ...     char_freq_;  char_freq_(  \\\n",
       "0             0.00            0.00   ...            0.00        0.000   \n",
       "1             0.00            0.94   ...            0.00        0.132   \n",
       "2             0.64            0.25   ...            0.01        0.143   \n",
       "3             0.31            0.63   ...            0.00        0.137   \n",
       "4             0.31            0.63   ...            0.00        0.135   \n",
       "\n",
       "   char_freq_[  char_freq_!  char_freq_$  char_freq_#  \\\n",
       "0          0.0        0.778        0.000        0.000   \n",
       "1          0.0        0.372        0.180        0.048   \n",
       "2          0.0        0.276        0.184        0.010   \n",
       "3          0.0        0.137        0.000        0.000   \n",
       "4          0.0        0.135        0.000        0.000   \n",
       "\n",
       "   capital_run_length_average  capital_run_length_longest  \\\n",
       "0                       3.756                        61.0   \n",
       "1                       5.114                       101.0   \n",
       "2                       9.821                       485.0   \n",
       "3                       3.537                        40.0   \n",
       "4                       3.537                        40.0   \n",
       "\n",
       "   capital_run_length_total  is_spam  \n",
       "0                     278.0      1.0  \n",
       "1                    1028.0      1.0  \n",
       "2                    2259.0      1.0  \n",
       "3                     191.0      1.0  \n",
       "4                     191.0      1.0  \n",
       "\n",
       "[5 rows x 58 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spambase.head(5) # Display the 5 first rows of the dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 1\n",
    "\n",
    "1. How many attributes are there in the dataset (i.e. number of columns)?\n",
    "2. How many observations (i.e. number of rows)?\n",
    "3. Display the mean and standard deviation of each attribute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of attributes: 58\n",
      "Number of observations: 4601\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word_freq_make</th>\n",
       "      <th>word_freq_address</th>\n",
       "      <th>word_freq_all</th>\n",
       "      <th>word_freq_3d</th>\n",
       "      <th>word_freq_our</th>\n",
       "      <th>word_freq_over</th>\n",
       "      <th>word_freq_remove</th>\n",
       "      <th>word_freq_internet</th>\n",
       "      <th>word_freq_order</th>\n",
       "      <th>word_freq_mail</th>\n",
       "      <th>...</th>\n",
       "      <th>char_freq_;</th>\n",
       "      <th>char_freq_(</th>\n",
       "      <th>char_freq_[</th>\n",
       "      <th>char_freq_!</th>\n",
       "      <th>char_freq_$</th>\n",
       "      <th>char_freq_#</th>\n",
       "      <th>capital_run_length_average</th>\n",
       "      <th>capital_run_length_longest</th>\n",
       "      <th>capital_run_length_total</th>\n",
       "      <th>is_spam</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>4601.000000</td>\n",
       "      <td>4601.000000</td>\n",
       "      <td>4601.000000</td>\n",
       "      <td>4601.000000</td>\n",
       "      <td>4601.000000</td>\n",
       "      <td>4601.000000</td>\n",
       "      <td>4601.000000</td>\n",
       "      <td>4601.000000</td>\n",
       "      <td>4601.000000</td>\n",
       "      <td>4601.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>4601.000000</td>\n",
       "      <td>4601.000000</td>\n",
       "      <td>4601.000000</td>\n",
       "      <td>4601.000000</td>\n",
       "      <td>4601.000000</td>\n",
       "      <td>4601.000000</td>\n",
       "      <td>4601.000000</td>\n",
       "      <td>4601.000000</td>\n",
       "      <td>4601.000000</td>\n",
       "      <td>4601.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.104553</td>\n",
       "      <td>0.213015</td>\n",
       "      <td>0.280656</td>\n",
       "      <td>0.065425</td>\n",
       "      <td>0.312223</td>\n",
       "      <td>0.095901</td>\n",
       "      <td>0.114208</td>\n",
       "      <td>0.105295</td>\n",
       "      <td>0.090067</td>\n",
       "      <td>0.239413</td>\n",
       "      <td>...</td>\n",
       "      <td>0.038575</td>\n",
       "      <td>0.139030</td>\n",
       "      <td>0.016976</td>\n",
       "      <td>0.269071</td>\n",
       "      <td>0.075811</td>\n",
       "      <td>0.044238</td>\n",
       "      <td>5.191515</td>\n",
       "      <td>52.172789</td>\n",
       "      <td>283.289285</td>\n",
       "      <td>0.394045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.305358</td>\n",
       "      <td>1.290575</td>\n",
       "      <td>0.504143</td>\n",
       "      <td>1.395151</td>\n",
       "      <td>0.672513</td>\n",
       "      <td>0.273824</td>\n",
       "      <td>0.391441</td>\n",
       "      <td>0.401071</td>\n",
       "      <td>0.278616</td>\n",
       "      <td>0.644755</td>\n",
       "      <td>...</td>\n",
       "      <td>0.243471</td>\n",
       "      <td>0.270355</td>\n",
       "      <td>0.109394</td>\n",
       "      <td>0.815672</td>\n",
       "      <td>0.245882</td>\n",
       "      <td>0.429342</td>\n",
       "      <td>31.729449</td>\n",
       "      <td>194.891310</td>\n",
       "      <td>606.347851</td>\n",
       "      <td>0.488698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.588000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.065000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.276000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>95.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.420000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.380000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.160000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.188000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.315000</td>\n",
       "      <td>0.052000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.706000</td>\n",
       "      <td>43.000000</td>\n",
       "      <td>266.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>4.540000</td>\n",
       "      <td>14.280000</td>\n",
       "      <td>5.100000</td>\n",
       "      <td>42.810000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>5.880000</td>\n",
       "      <td>7.270000</td>\n",
       "      <td>11.110000</td>\n",
       "      <td>5.260000</td>\n",
       "      <td>18.180000</td>\n",
       "      <td>...</td>\n",
       "      <td>4.385000</td>\n",
       "      <td>9.752000</td>\n",
       "      <td>4.081000</td>\n",
       "      <td>32.478000</td>\n",
       "      <td>6.003000</td>\n",
       "      <td>19.829000</td>\n",
       "      <td>1102.500000</td>\n",
       "      <td>9989.000000</td>\n",
       "      <td>15841.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 58 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       word_freq_make  word_freq_address  word_freq_all  word_freq_3d  \\\n",
       "count     4601.000000        4601.000000    4601.000000   4601.000000   \n",
       "mean         0.104553           0.213015       0.280656      0.065425   \n",
       "std          0.305358           1.290575       0.504143      1.395151   \n",
       "min          0.000000           0.000000       0.000000      0.000000   \n",
       "25%          0.000000           0.000000       0.000000      0.000000   \n",
       "50%          0.000000           0.000000       0.000000      0.000000   \n",
       "75%          0.000000           0.000000       0.420000      0.000000   \n",
       "max          4.540000          14.280000       5.100000     42.810000   \n",
       "\n",
       "       word_freq_our  word_freq_over  word_freq_remove  word_freq_internet  \\\n",
       "count    4601.000000     4601.000000       4601.000000         4601.000000   \n",
       "mean        0.312223        0.095901          0.114208            0.105295   \n",
       "std         0.672513        0.273824          0.391441            0.401071   \n",
       "min         0.000000        0.000000          0.000000            0.000000   \n",
       "25%         0.000000        0.000000          0.000000            0.000000   \n",
       "50%         0.000000        0.000000          0.000000            0.000000   \n",
       "75%         0.380000        0.000000          0.000000            0.000000   \n",
       "max        10.000000        5.880000          7.270000           11.110000   \n",
       "\n",
       "       word_freq_order  word_freq_mail     ...       char_freq_;  char_freq_(  \\\n",
       "count      4601.000000     4601.000000     ...       4601.000000  4601.000000   \n",
       "mean          0.090067        0.239413     ...          0.038575     0.139030   \n",
       "std           0.278616        0.644755     ...          0.243471     0.270355   \n",
       "min           0.000000        0.000000     ...          0.000000     0.000000   \n",
       "25%           0.000000        0.000000     ...          0.000000     0.000000   \n",
       "50%           0.000000        0.000000     ...          0.000000     0.065000   \n",
       "75%           0.000000        0.160000     ...          0.000000     0.188000   \n",
       "max           5.260000       18.180000     ...          4.385000     9.752000   \n",
       "\n",
       "       char_freq_[  char_freq_!  char_freq_$  char_freq_#  \\\n",
       "count  4601.000000  4601.000000  4601.000000  4601.000000   \n",
       "mean      0.016976     0.269071     0.075811     0.044238   \n",
       "std       0.109394     0.815672     0.245882     0.429342   \n",
       "min       0.000000     0.000000     0.000000     0.000000   \n",
       "25%       0.000000     0.000000     0.000000     0.000000   \n",
       "50%       0.000000     0.000000     0.000000     0.000000   \n",
       "75%       0.000000     0.315000     0.052000     0.000000   \n",
       "max       4.081000    32.478000     6.003000    19.829000   \n",
       "\n",
       "       capital_run_length_average  capital_run_length_longest  \\\n",
       "count                 4601.000000                 4601.000000   \n",
       "mean                     5.191515                   52.172789   \n",
       "std                     31.729449                  194.891310   \n",
       "min                      1.000000                    1.000000   \n",
       "25%                      1.588000                    6.000000   \n",
       "50%                      2.276000                   15.000000   \n",
       "75%                      3.706000                   43.000000   \n",
       "max                   1102.500000                 9989.000000   \n",
       "\n",
       "       capital_run_length_total      is_spam  \n",
       "count               4601.000000  4601.000000  \n",
       "mean                 283.289285     0.394045  \n",
       "std                  606.347851     0.488698  \n",
       "min                    1.000000     0.000000  \n",
       "25%                   35.000000     0.000000  \n",
       "50%                   95.000000     0.000000  \n",
       "75%                  266.000000     1.000000  \n",
       "max                15841.000000     1.000000  \n",
       "\n",
       "[8 rows x 58 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Your code goes here\n",
    "# 1-2: Number of attributes and observations\n",
    "print('Number of attributes:', spambase.shape[1])\n",
    "print('Number of observations:', spambase.shape[0])\n",
    "# 3. Display mean, standard deviation and other summary statistics for all attributes\n",
    "spambase.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now want to *remove* some of the attributes from our data. There are various reasons for wanting to do so, for instance we might think that these are not relevant to the task we want to perform (i.e. e-mail classification) or they might have been contaminated with noise during the data collection process."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 2\n",
    "\n",
    "1. Delete the `capital_run_length_average`, `capital_run_length_longest` and  `capital_run_length_total` attributes. *Hint*: You should make use of the [`drop`](http://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.drop.html) method.\n",
    "\n",
    "2. Display the new number of attributes. Does it look like what you expected?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of attributes after deletion: 55\n"
     ]
    }
   ],
   "source": [
    "# Your code here\n",
    "spambase = spambase.drop([\"capital_run_length_average\", \"capital_run_length_longest\", \"capital_run_length_total\"], axis=1)\n",
    "print('Number of attributes after deletion:', spambase.shape[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The remaining attributes represent relative frequencies of various important words and characters in emails. This is true for all attributes except `is_spam` which represents whether the e-mail was annotated as spam or not. So each e-mail is represented by a 55 dimensional vector representing whether or not a particular word exists in an e-mail. This is the so called [bag of words](http://en.wikipedia.org/wiki/Bag_of_words_model) representation and is clearly a very crude approximation since it does not take into account the order of the words in the emails.\n",
    "\n",
    "Now let's get a feeling of the distribution of ham (i.e. valid) vs. spam emails. We can do this by using a [countplot](https://stanford.edu/~mwaskom/software/seaborn/generated/seaborn.countplot.html) in seaborn.\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 3\n",
    "\n",
    "1. By using seaborn produce a countplott hat shows the distribution of ham/spam e-mails.\n",
    "2. Modify the labels on the x axis (`xticklabels`) to `Ham` and `Spam` (by default they should be set to `0.0` and `1.0`).\n",
    "3. Remove the `is_spam` label from the x axis (`xlabel`) since it does not add any information to the graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.text.Text at 0x1b4b2668>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYkAAAECCAYAAAALqiumAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nLuhpXNUAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x6747128>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Your code goes here\n",
    "ax = sns.countplot(x='is_spam', data=spambase)\n",
    "ax.set_xticklabels(['Ham', 'Spam'])\n",
    "plt.xlabel('')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we want to simplify the problem by transforming our dataset. We will replace all numerical values which represent word frequencies with a binary value representing whether each word was present in a document or not."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 4\n",
    "\n",
    "1. Crate a new dataframe called `spambase_binary` from `spambase`. *Hint*: Look into the [`copy`](http://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.copy.html) method in pandas.\n",
    "\n",
    "2. Convert all attributes in `spambase_binary` to Boolean values: 1 if the word or character is present in the email, or 0 otherwise.\n",
    "\n",
    "3. Display the 5 last observations of the transformed dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word_freq_make</th>\n",
       "      <th>word_freq_address</th>\n",
       "      <th>word_freq_all</th>\n",
       "      <th>word_freq_3d</th>\n",
       "      <th>word_freq_our</th>\n",
       "      <th>word_freq_over</th>\n",
       "      <th>word_freq_remove</th>\n",
       "      <th>word_freq_internet</th>\n",
       "      <th>word_freq_order</th>\n",
       "      <th>word_freq_mail</th>\n",
       "      <th>...</th>\n",
       "      <th>word_freq_edu</th>\n",
       "      <th>word_freq_table</th>\n",
       "      <th>word_freq_conference</th>\n",
       "      <th>char_freq_;</th>\n",
       "      <th>char_freq_(</th>\n",
       "      <th>char_freq_[</th>\n",
       "      <th>char_freq_!</th>\n",
       "      <th>char_freq_$</th>\n",
       "      <th>char_freq_#</th>\n",
       "      <th>is_spam</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4596</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4597</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4598</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4599</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4600</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 55 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      word_freq_make  word_freq_address  word_freq_all  word_freq_3d  \\\n",
       "4596             1.0                0.0            1.0           0.0   \n",
       "4597             0.0                0.0            0.0           0.0   \n",
       "4598             1.0                0.0            1.0           0.0   \n",
       "4599             1.0                0.0            0.0           0.0   \n",
       "4600             0.0                0.0            1.0           0.0   \n",
       "\n",
       "      word_freq_our  word_freq_over  word_freq_remove  word_freq_internet  \\\n",
       "4596            0.0             1.0               0.0                 0.0   \n",
       "4597            0.0             0.0               0.0                 0.0   \n",
       "4598            0.0             0.0               0.0                 0.0   \n",
       "4599            1.0             0.0               0.0                 0.0   \n",
       "4600            0.0             0.0               0.0                 0.0   \n",
       "\n",
       "      word_freq_order  word_freq_mail   ...     word_freq_edu  \\\n",
       "4596              0.0             0.0   ...               1.0   \n",
       "4597              0.0             0.0   ...               1.0   \n",
       "4598              0.0             0.0   ...               1.0   \n",
       "4599              0.0             0.0   ...               1.0   \n",
       "4600              0.0             0.0   ...               1.0   \n",
       "\n",
       "      word_freq_table  word_freq_conference  char_freq_;  char_freq_(  \\\n",
       "4596              0.0                   0.0          0.0          1.0   \n",
       "4597              0.0                   0.0          0.0          0.0   \n",
       "4598              0.0                   0.0          1.0          1.0   \n",
       "4599              0.0                   0.0          0.0          1.0   \n",
       "4600              0.0                   0.0          0.0          0.0   \n",
       "\n",
       "      char_freq_[  char_freq_!  char_freq_$  char_freq_#  is_spam  \n",
       "4596          0.0          0.0          0.0          0.0      0.0  \n",
       "4597          0.0          1.0          0.0          0.0      0.0  \n",
       "4598          0.0          0.0          0.0          0.0      0.0  \n",
       "4599          0.0          0.0          0.0          0.0      0.0  \n",
       "4600          0.0          1.0          0.0          0.0      0.0  \n",
       "\n",
       "[5 rows x 55 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Your code goes here\n",
    "\n",
    "spambase_binary = spambase.copy(deep=True)\n",
    "spambase_binary[spambase_binary>0]=1\n",
    "spambase_binary.tail(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualisation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we want to get a rough feeling of how the presence or absence of some specific words would affect the outcome of interest (whether an email is classifed as *ham* or *spam*). We will be focusing on three specific words, namely `make`, `internet` and `edu`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 5\n",
    "\n",
    "1. By using seaborn produce three [countplots](https://stanford.edu/~mwaskom/software/seaborn/generated/seaborn.countplot.html) each of which shows the presence/absence counts of the words `make`, `internet` and `edu`. Do this separately for the *spam* and *ham* emails, but show the counts on a single graph for each word. *Hint*: use the `hue` input argument for the countplots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfkAAAJfCAYAAAB8G6+KAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nWOZ0AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1b8aa470>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Your code goes here\n",
    "words_of_interest = ['word_freq_' + word for word in ['make', 'internet', 'edu']]\n",
    "n_words = len(words_of_interest)\n",
    "plt.subplots(n_words, figsize=(8,10))\n",
    "for i, word in enumerate(words_of_interest):\n",
    "    plt.subplot(n_words,1,i+1)\n",
    "    ax = sns.countplot(x=word, hue='is_spam', data=spambase_binary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multinomial Naive Bayes classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given the transformed dataset, we now wish to train a Naïve Bayes classifier to distinguish spam from regular email by fitting a distribution of the number of occurrences of each word for all the spam and non-spam e-mails. Read about the [Naive Bayes classifier](https://en.wikipedia.org/wiki/Naive_Bayes_classifier) and the underlying assumption if you are not already familiar with it. In this lab we focus on the [Multinomial Naive Bayes classifier](https://en.wikipedia.org/wiki/Naive_Bayes_classifier#Multinomial_naive_Bayes). \n",
    "\n",
    "We will make use of the `MultinomialNB` class in `sklearn`. Check out the user guide [description](http://scikit-learn.org/stable/modules/naive_bayes.html#multinomial-naive-bayes) and [documentation](http://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.MultinomialNB.html#sklearn.naive_bayes.MultinomialNB) to familiriase yourself with this class. The `MultinomialNB` module should be already imported, otherwise import it now."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All classifiers in `sklearn` implement a `fit()` and `predict()` method. The first learns the parameters of the model and the latter classifies -potentially new- inputs. For a Naive Bayes classifier, the [`fit()`](http://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.GaussianNB.html#sklearn.naive_bayes.GaussianNB.fit) method takes at least two input arguments `X` and `y`, where `X` are the input features and `y` are the labels associated with each example in the training dataset (i.e. targets). \n",
    "\n",
    "As a first step we extract the input features and targets from the DataFrame. To do so, we will use the [`values`](http://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.values.html) property. For the input features we want to select all columns except `is_spam` and for this we may use the [`drop`](http://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.drop.html) method which discards the specified columns along the given axis. In fact, we can combine these two operations in one step."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 6\n",
    "\n",
    "1. Extract a numpy array from the `spambase_binary` which contains the values for all columns except `is_spam`. *Hint*: make use of the `drop` method and `values` property. Store the array in variable `X`\n",
    "2. Extract the targets from `spambase_binary` by using indexing. Store the array in variable `y`.\n",
    "3. Display the dimensionality (i.e. `shape`) of each of the two arrays. *Hint:* The shape of `X` and `y` should be `(4601L, 54L)` and `(4601L,)` respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input features shape: (4601L, 54L)\n",
      "Targets shape: (4601L,)\n"
     ]
    }
   ],
   "source": [
    "# Your code goes here\n",
    "X = spambase_binary.drop('is_spam', axis=1).values\n",
    "y = spambase_binary['is_spam'].values\n",
    "print('Input features shape:', X.shape)\n",
    "print('Targets shape:', y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 6\n",
    "\n",
    "Now we want to train a Multinomial Naive Bayes classifier. Initialise a `MultinomialNB` object and [`fit`](http://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.MultinomialNB.html#sklearn.naive_bayes.MultinomialNB.fit) the classifier by using the `X` and `y` arrays extracted in the cell above. Do not use the `sample_weight` option at this stage (i.e. let `sklearn` to use the default option)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Your code goes here\n",
    "mnb = MultinomialNB()\n",
    "mnb.fit(X=X, y=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can get a feeling of how good the fit is by feeding the training data in our classifier and looking at the classification score and the produced [confusion matrix](https://en.wikipedia.org/wiki/Confusion_matrix). \n",
    "\n",
    "Scikit-learn has an implemented method for the `MultinomialNB` which estimates the classification accuracy score. This method is called [`score`](http://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.MultinomialNB.html#sklearn.naive_bayes.MultinomialNB.score). Alternatively, you can compute the prediction for the training data and make use of the [`accuracy_score`](http://scikit-learn.org/stable/modules/generated/sklearn.metrics.accuracy_score.html) metric (that is in fact what the classifier's `score()` method does under the hood).\n",
    "\n",
    "Scikit-learn also has a [`confusion_matrix`](http://scikit-learn.org/stable/modules/generated/sklearn.metrics.confusion_matrix.html#sklearn.metrics.confusion_matrix) implementation which reutrns a numpy array (square matrix) of dimensionality `K`, where `K` is the number of classes which is 2 in our case."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 7 \n",
    "\n",
    "1. Display the log-prior probabilities for each class. *Hint:* use tab-completion to figure out which attribute of the `MultinomialNB` structure you are interested in.\n",
    "2. Predict the output of the classifier by using the training data as input. *Hint*: make use of the `predict` method of the `MultinomialNB` classifier.\n",
    "3. Compute the classification accuracy on the training data by either using the `accuracy_score` metric or the `score` method of the `MultinomialNB`. \n",
    "4. Compute the resulting confusion_matrix by using the builtin scikit-learn class and display the result. \n",
    "5. Normalise the produced confusion matrix by row (i.e. you want to make each row to sum up to 1.) and display the result.\n",
    "6. By making use of the `plot_confusion_matrix` provided below, visualise the normalised confusion matrix. Plot the appropriate labels on both axes by making use of the `classes` input argument."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(cm, classes=None, title='Confusion matrix'):\n",
    "    \"\"\"Plots a confusion matrix.\"\"\"\n",
    "    if classes is not None:\n",
    "        sns.heatmap(cm, xticklabels=classes, yticklabels=classes, vmin=0., vmax=1., annot=True)\n",
    "    else:\n",
    "        sns.heatmap(cm, vmin=0., vmax=1.)\n",
    "    plt.title(title)\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class log-priors: [-0.50094918 -0.93129074]\n",
      "Classification accuracy on training data: 0.892414692458\n",
      "Confusion matrix for training data:\n",
      " [[2412  376]\n",
      " [ 119 1694]]\n",
      "Normalised confusion matrix for training data:\n",
      " [[ 0.8651363   0.1348637 ]\n",
      " [ 0.06563707  0.93436293]]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWoAAAEZCAYAAAC+bm+MAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1beca390>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Your code goes here \n",
    "\n",
    "# 1. log-priors\n",
    "print('Class log-priors:', mnb.class_log_prior_)\n",
    "# 2. prediction\n",
    "tr_pred = mnb.predict(X=X)\n",
    "# 3. classification accuracy\n",
    "ca = accuracy_score(y, mnb.predict(X)) # or ca = gnb.score(X,y)\n",
    "print('Classification accuracy on training data:', ca)\n",
    "# 4. cofusion matrix\n",
    "cm = confusion_matrix(y, tr_pred)\n",
    "print('Confusion matrix for training data:\\n', cm)\n",
    "# 5. normalise confusion matrix\n",
    "cm_norm = cm/cm.sum(axis=1)[:, np.newaxis]\n",
    "print('Normalised confusion matrix for training data:\\n', cm_norm)\n",
    "# 6. confusion matrix visualisation\n",
    "plt.figure()\n",
    "plot_confusion_matrix(cm_norm, classes=['ham', 'spam'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 8\n",
    "\n",
    "Study the output produced, most importantly the percentages of correctly and incorrectly classified instances. You probably will notice that your classifer does rather well despite making a very strong assumption on the form of the data. What would be the main practical problems we would face if we were not to make this assumption for this particular dataset? *Hint*: think of the fundamental assumption the Naive Bayes model does."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Your answer here:*\n",
    "\n",
    "The classifier is doing well, but it's only been tested so far on the same data we used for training it, so we can't be sure that it can generalise to new examples. \n",
    "\n",
    "The main practical problem if we didn't make the Naive Bayes assumption (conditional independence given the label) we would have to estimate a full covariance matrix of size 55 X 55 (i.e. ~1500 parameters) and we only have 4000 samples, so the covariance estimate might be particularly noisy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The empirical log probability of input features given a class $P\\left(x_i  |  y\\right)$ is given by the attribute `feature_log_prob` of the classifier. For each feature there are two such conditional probabilities, one for each class. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 9\n",
    "\n",
    "1. What dimensionality do you expect the `feature_log_prob_` array to have?\n",
    "2. Inspect the log probabilities of the features. Verify that it has the expected dimensionality (i.e. `shape`).\n",
    "3. Find the features (indices) that have higher log probability when the email is spam. *Hint:* you might want to use a boolean expression and the [`np.argwhere`](http://docs.scipy.org/doc/numpy/reference/generated/numpy.argwhere.html) method on top of that. The resulting structure will be an array, but you might want to convert it into a python list by using the [`tolist`](http://docs.scipy.org/doc/numpy/reference/generated/numpy.ndarray.tolist.html) method.\n",
    "4. Display the words or characters that are associated with these probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2L, 54L)\n",
      "Index([u'word_freq_will', u'word_freq_you', u'word_freq_hp', u'word_freq_hpl',\n",
      "       u'word_freq_george', u'word_freq_650', u'word_freq_lab',\n",
      "       u'word_freq_labs', u'word_freq_telnet', u'word_freq_857',\n",
      "       u'word_freq_data', u'word_freq_415', u'word_freq_85',\n",
      "       u'word_freq_technology', u'word_freq_1999', u'word_freq_parts',\n",
      "       u'word_freq_pm', u'word_freq_direct', u'word_freq_cs',\n",
      "       u'word_freq_meeting', u'word_freq_original', u'word_freq_project',\n",
      "       u'word_freq_re', u'word_freq_edu', u'word_freq_table',\n",
      "       u'word_freq_conference', u'char_freq_;', u'char_freq_(',\n",
      "       u'char_freq_['],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Your code goes here\n",
    "# 1-2\n",
    "# It has to be (2,54)\n",
    "print(mnb.feature_log_prob_.shape)\n",
    "# 3-4 Features with higher log probability for ham\n",
    "feats = np.argwhere(mnb.feature_log_prob_[0] > mnb.feature_log_prob_[1]).squeeze().tolist()\n",
    "print(spambase.columns[feats])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the final part of this section we will now pretend we are spammers wishing to fool a spam checking system based on Naïve Bayes into classifying a spam e-mail as ham (i.e. a valid e-mail). For this we will use a test set consisting of just one data point (i.e. e-mail). This tiny dataset is called `spambase_test` and has already been pre-processed for you which means that the redundant attributes have been removed and word frequencies have been replaced by word presence/absence."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 10\n",
    "\n",
    "1. Load the `spambase_test.csv` dataset into a new pandas structure. You don't need to apply any further transformations at this stage.\n",
    "2. Feed the input features into the classifier and compare the outcome to the true label. Make sure you don't feed the target into the classifier as you will receive an error (why?). Does the classifer classify the spam e-mail correctly?\n",
    "3. Pick one (perhaps random) attribute that has higher probability for the ham class and set the corresponding value in `spambase_test` to 1. Now predict the new outcome. Has it changed? If not, keep modifying more attributes until you have achieved the desired outcome (i.e. model classifies the e-mail as ham).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actual label:  1  Prediction:  [1]\n",
      "The word \" hp \" did the trick!\n"
     ]
    }
   ],
   "source": [
    "# Your code goes here\n",
    "#1. \n",
    "data_path_test = os.path.join(os.getcwd(), 'datasets', 'spambase_test.csv')\n",
    "spambase_test = pd.read_csv(data_path_test, delimiter = ',')\n",
    "\n",
    "#2.\n",
    "prediction = mnb.predict(spambase_test.drop('is_spam', axis=1).values)\n",
    "print('Actual label: ', spambase_test.iloc[0]['is_spam'], ' Prediction: ', prediction.astype(np.int))\n",
    "\n",
    "#3. Loop until prediction is ham\n",
    "for attribute in spambase.columns[feats]:\n",
    "    spambase_test.iloc[0][attribute] = 1\n",
    "    prediction = mnb.predict(spambase_test.drop('is_spam', axis=1).values)\n",
    "    if prediction != spambase_test.iloc[0]['is_spam']:\n",
    "        print('The word \"', attribute[10:], '\" did the trick!')\n",
    "        break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
